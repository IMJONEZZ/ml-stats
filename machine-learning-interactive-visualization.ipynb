{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import random\n",
    "import itertools\n",
    "from matplotlib import colors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ml_plotting_functions\n",
    "\n",
    "mpl.rcParams['figure.dpi'] = 150 # Increase size in Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# The plotting functions for the three main views\n",
    "##################################################\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "\n",
    "def plot_marbles_with_truth_color(class_imbalance, n_x=10, n_y=10):\n",
    "    fig, ax = plt.subplots(ncols=1, figsize=(3, 3))\n",
    "\n",
    "    # data prep\n",
    "    df['coords'] = list(itertools.product(*[range(n_x), range(n_y)]))\n",
    "    df['true_values'] = [int(random.random() + class_imbalance) for _ in range(n_x * n_y)]\n",
    "    df['true_colors'] = df['true_values'].apply(lambda v: ml_plotting_functions.DEFAULT_MARBLE_COLOR  if v == 1 else 'white')\n",
    "\n",
    "    # actual plotting\n",
    "    ml_plotting_functions.draw_value_circles(ax, df['true_colors'], df['coords'])\n",
    "\n",
    "    # finalize\n",
    "    fig.suptitle(\"How the truth looks like\")\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def plot_classifier_view(quality):\n",
    "    fig, [ax1, ax2] = plt.subplots(nrows=1, ncols=2, figsize=(6, 3))\n",
    "\n",
    "    # data prep\n",
    "    df['predicted_values'] = ml_plotting_functions.predict_values(df['true_values'], quality=quality)\n",
    "    df['predicted_value_colors'] = df['predicted_values'].astype(str)\n",
    "    df['face_colors'] = df['predicted_values'].apply(lambda c: tuple(list(colors.to_rgb(ml_plotting_functions.DEFAULT_MARBLE_COLOR)) + [c]))\n",
    "\n",
    "    # actual plotting\n",
    "    ml_plotting_functions.draw_value_circles(ax1, df['face_colors'], df['coords'])\n",
    "    ml_plotting_functions.plot_predicted_values_as_swarmplot_with_color_gradient(ax2,\n",
    "                                                           df.sort_values('predicted_values')['predicted_values'],  # since for the swarm plot, marker order is sorted by value\n",
    "                                                           s=10)\n",
    "    # finalize\n",
    "    fig.suptitle(\"How the classifier sees it\")\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def plot_evaluation_metrics(cutoff):\n",
    "    fig, [ax1, ax2, ax3] = plt.subplots(nrows=1, ncols=3, figsize=(12, 3))\n",
    "\n",
    "    # data prep\n",
    "    df['predicted_binary_values'] = df['predicted_values'].apply(lambda x: 0 if x < cutoff else 1)\n",
    "    df_sorted = df.sort_values('predicted_values')\n",
    "\n",
    "    # actual plotting\n",
    "    ml_plotting_functions.plot_predicted_values_as_swarmplot_with_green_red_outline(ax1,\n",
    "                                                              df_sorted['true_values'],\n",
    "                                                              df_sorted['predicted_values'],\n",
    "                                                              df_sorted['predicted_binary_values'], cutoff)\n",
    "    ml_plotting_functions.make_roc_curve_plot(ax2, df['true_values'], df['predicted_values'], cutoff)\n",
    "    ml_plotting_functions.make_precision_recall_bar_chart(ax3, df['true_values'], df['predicted_binary_values'])\n",
    "\n",
    "    # finalize\n",
    "    fig.suptitle(\"Evaluation metrics with cutoff\\n\", va='bottom')\n",
    "    plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Setup widgets, interactivity & layout\n",
    "##################################################\n",
    "\n",
    "# Create the widgets\n",
    "class_imbalance_widget = widgets.FloatSlider(min=0.1,\n",
    "                                             max=0.9,\n",
    "                                             step=0.1,\n",
    "                                             value=0.5,\n",
    "                                             continuous_update=False,\n",
    "                                             description='Class imbalance',\n",
    "                                             style={'description_width': 'initial'})\n",
    "\n",
    "quality_widget = widgets.FloatSlider(min=0,\n",
    "                                     max=1,\n",
    "                                     step=0.1,\n",
    "                                     value=0.5,\n",
    "                                     continuous_update=False,\n",
    "                                     description='Classifier strength',\n",
    "                                     style={'description_width': 'initial'})\n",
    "\n",
    "cutoff_widget = widgets.FloatSlider(min=0,\n",
    "                                    max=1,\n",
    "                                    step=0.05,\n",
    "                                    value=0.5,\n",
    "                                    continuous_update=False,\n",
    "                                    description='Cutoff value',\n",
    "                                    style={'description_width': 'initial'})\n",
    "\n",
    "\n",
    "# Create the views\n",
    "truth_view = widgets.interactive(plot_marbles_with_truth_color,\n",
    "                                 class_imbalance=class_imbalance_widget,\n",
    "                                 n_x=widgets.fixed(10),\n",
    "                                 n_y=widgets.fixed(10))\n",
    "classifier_view = widgets.interactive(plot_classifier_view, quality=quality_widget)\n",
    "metrics_view = widgets.interactive(plot_evaluation_metrics, cutoff=cutoff_widget)\n",
    "\n",
    "# In case of value change, update downstream views\n",
    "class_imbalance_widget.observe(lambda x: classifier_view.update(), 'value')\n",
    "class_imbalance_widget.observe(lambda x: metrics_view.update(), 'value')\n",
    "quality_widget.observe(lambda x: metrics_view.update(), 'value')\n",
    "\n",
    "# Put the views into a layout grid\n",
    "grid = widgets.GridspecLayout(2, 3, layout=widgets.Layout(justify_content='center'))\n",
    "grid[0, 0] = truth_view\n",
    "grid[0, 1:] = classifier_view\n",
    "grid[1, :] = metrics_view\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Make the app\n",
    "##################################################\n",
    "\n",
    "title_html = \"\"\"\n",
    "<h2>Machine Learning Model Evaluation: Visual & Interactive</h2>\n",
    "\n",
    "<ul style=\"line-height: 1.5\">\n",
    "  <li>A classifier was trained to identify positive targets, here visualized as blue marbles (upper left).\n",
    "The ratio of negative (white) and positive (blue) targets can be controlled via the slider.</li>\n",
    "\n",
    "  <li>The strength-adjustable classifier then predicts a score from one to zero for each item (upper center and right).</li>\n",
    "  \n",
    "  <li>Based on this score and an adjustable cutoff threshold, each item is classified as either positive or negative.\n",
    "Correct or incorrect classification is highlighted with a green or red outline for each circle (lower left). \n",
    "Subsequently, \n",
    "<a href=\"https://en.wikipedia.org/wiki/Receiver_operating_characteristic\"> the ROC curve and the AUC value<a>\n",
    "(lower center) as well as\n",
    "<a href=\"https://en.wikipedia.org/wiki/Precision_and_recall\"> precision, recall</a> \n",
    "and \n",
    "<a href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification\"> accuracy </a> \n",
    "(lower right) can be calculated.</li>\n",
    "</ul>\n",
    "\"\"\"\n",
    "\n",
    "description_html = \"\"\"\n",
    "<style>\n",
    "p {\n",
    "    margin-bottom: 1.2em;\n",
    "    line-height: 1.5;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<p>The effects of different configurations regarding class imbalance, model strength or cutoff threshold on evaluation metrics can be studied.\n",
    "Also, the relationship between these metrics, e.g. the tradeoff between precision and recall, can be observed.</p>\n",
    "\n",
    "<p>This allows e.g. to explore the problem with accuracy for unbalanced classes: In the case of few positive targets, \n",
    "a weak classifier with a high threshold will yield a high accuracy simply due to labelling everything negative.</p>\n",
    "\n",
    "<p>Source code <a href=\"https://github.com/dhaitz/machine-learning-interactive-visualization\"> here</a>. Ideas, suggestions and improvements welcome! /<a href=\"https://dhaitz.github.io\">dh</a></p>\n",
    "\"\"\"\n",
    "app_contents = [widgets.HTML(title_html, layout=widgets.Layout(margin='0 0 3em 0', max_width='800px')),\n",
    "            grid,\n",
    "            widgets.HTML(description_html, layout=widgets.Layout(margin='3em 0 0 0', max_width='800px'))]\n",
    "app = widgets.VBox(app_contents, layout=widgets.Layout(max_width='1024px', margin='0 auto 0 auto'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebde8e8a17684f4d8dc9f0a7b8fe425f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='\\n<h2>Machine Learning Model Evaluation: Visual & Interactive</h2>\\n\\n<ul style=\"li…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(app)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
